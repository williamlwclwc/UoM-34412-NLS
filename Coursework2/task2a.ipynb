{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2a Sentiment Analysis of Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "corpus_root = \"./corpus2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos tagging all files\n",
    "newcorpus = PlaintextCorpusReader(corpus_root, \".*\", encoding='latin-1')\n",
    "# print(newcorpus.words())\n",
    "corpus2_words = newcorpus.words()\n",
    "corpus2_words = pos_tag(corpus2_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Sentiment Lexicon by Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial lexicon of adjectives\n",
    "neg_init = ['silly', 'sour', 'cynical', 'amateurish', 'offensive', 'stupid', 'dishonest', 'r-rated', \n",
    "            'rough', 'unsuccessful', 'unfunny', 'repetitive', 'sappy', 'dull', 'dry', 'mush-hearted', 'predictable', \n",
    "            'creepy', 'neurotic', 'disturbing']\n",
    "pos_init = ['inspiring', 'exotic', 'good-looking', 'effective', 'gripping', 'thrilling', 'intriguing',\n",
    "            'satisfying', 'entertaining', 'stylish', 'funny', 'emotional', 'naturalistic', 'romantic', \n",
    "            'resonant', 'brilliant', 'absorbing', 'fresh', 'lyrical', 'honest', 'clever']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'silly': -999, 'sour': -999, 'cynical': -999, 'amateurish': -1000, 'offensive': -999, 'stupid': -999, 'dishonest': -999, 'r-rated': -999, 'rough': -999, 'unsuccessful': -999, 'unfunny': -999, 'repetitive': -999, 'sappy': -1000, 'dull': -999, 'dry': -999, 'mush-hearted': -999, 'predictable': -999, 'creepy': -999, 'neurotic': -999, 'disturbing': -999, 'inspiring': 999, 'exotic': 999, 'good-looking': 999, 'effective': 998, 'gripping': 999, 'thrilling': 999, 'intriguing': 999, 'satisfying': 999, 'entertaining': 1001, 'stylish': 1000, 'funny': 1001, 'emotional': 999, 'naturalistic': 999, 'romantic': 999, 'resonant': 999, 'brilliant': 999, 'absorbing': 999, 'fresh': 1000, 'lyrical': 999, 'honest': 999, 'clever': 1000, 'tedious': -1, 'mechanical': -2, 'loud': -1, 'sophomoric': -1, 'grainy': -1, 'intellectual': 2, 'raucous': -1, 'insistent': -1, 'sanguine': -1, 'banal': -1, 'clownish': -1, 'formulaic': -1, 'vital': 1, 'unentertaining': -1, 'affable': -1, 'plausible': 1, 'quirky': 1, 'concerned': -1, 'prosaic': -1, 'pretentious': -1, 'full': 1, 'talented': 1, 'moodily': -1, 'unrecommendable': -1, 'didactic': -1, 'familiar': -2, 'muddled': -1, 'sentimental': -1, 'stereotypical': -1, 'unsatisfying': 1, 'lazy': -1, 'strong': 1, 'audacious': 1, 'light': 1, 'shot': 2, 'ankle': -1, 'overwrought': -1, 'unoriginal': -1, 'monotonous': -1, 'interesting': 2, 'leaden': -1, 'redundant': -1, 'engaged': 1, 'wooden': -1, 'impenetrable': -1, 'true': 1, 'claustrophobic': 1, 'good': 1, 'delightful': 1, 'beautiful': 1, 'bold': 1, 'free': 1, 'unaffected': 1, 'uneven': -1, 'religious': 1, 'rapturous': 1, 'raw': 0, 'slow': -1, 'ingenious': 1, 'frisky': 1, 'authentic': 1, 'flavorful': 1, 'innocuous': -1, 'provocative': 1, 'flaky': 1, 'unselfconscious': 1, 'smug': -1, 'energetic': 2, 'exciting': 1, 'delectable': 1, 'slight': -1, 'accessible': 1, 'pure': 1, 'unique': 1, 'forceful': -1, 'intense': 1, 'insightful': 2, 'informative': 1, 'honorable': 1, 'poignant': 1, 'odd': 0, 'unsettling': 1, 'brutal': 2, 'simple': -1, 'complex': 1, 'human': 1, 'believable': 0, 'sensual': 1, 'sexual': 1, 'enjoyable': 1, 'dramatic': 1, 'handsome': 1, 'average': -1, 'tricky': 1, 'subtle': 1, 'touching': 1, 'serious': -1, 'pithy': 1, 'sweet': 1, 'moral': 1, 'suggestive': 1, 'dead': -1, 'charming': 1, 'steady': -1, 'sad': 1, 'deeply': 1, 'richly': 1, 'uplifting': 1, 'weird': 1, 'realistic': 1, 'suspenseful': 1, 'unexpected': 1, 'introspective': 1, 'spare': -1, 'crude': -1, 'melodramatic': -1, 'powerful': 1, 'smart': 1, 'cerebral': 1, 'celebratory': 1, 'old': 1, 'meditative': 1}\n"
     ]
    }
   ],
   "source": [
    "lexicon = {}\n",
    "for word in neg_init:\n",
    "    lexicon.update({word: -999})\n",
    "for word in pos_init:\n",
    "    lexicon.update({word: 999})\n",
    "\n",
    "# _ and X, X and _, _ but X, X but _ are the baseline patterns    \n",
    "for i in range(len(corpus2_words)):\n",
    "    x = corpus2_words[i][0]\n",
    "    if x in neg_init and i < len(corpus2_words)-1:\n",
    "        if corpus2_words[i-1][0] == 'and':\n",
    "            if corpus2_words[i-2][1] == 'JJ':\n",
    "                # _ and X\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] -= 1\n",
    "        elif corpus2_words[i-1][0] == 'but' or corpus2_words[i-1][0] == 'rather':\n",
    "            if corpus2_words[i-2][1] == 'JJ':\n",
    "                # _ but X / _ rather X\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] += 1\n",
    "        elif corpus2_words[i-2][0] == 'but' or corpus2_words[i-2][0] == 'rather':\n",
    "            if corpus2_words[i-3][1] == 'JJ':\n",
    "                # _ but adv X / _ rather than X\n",
    "                if lexicon.get(corpus2_words[i-3][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-3][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-3][0]] += 1\n",
    "        if corpus2_words[i+1][0] == 'and':\n",
    "            if corpus2_words[i+2][1] == 'JJ':\n",
    "                # X and _\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] -= 1\n",
    "        elif corpus2_words[i+1][0] == 'but' or corpus2_words[i+1][0] == 'rather':\n",
    "            if corpus2_words[i+2][1] == 'JJ':\n",
    "                # X but _ / X rather _\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] += 1\n",
    "            if corpus2_words[i+3][1] == 'JJ':\n",
    "                # X but adv _ / X rather than _\n",
    "                if lexicon.get(corpus2_words[i+3][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+3][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+3][0]] += 1\n",
    "        if corpus2_words[i+1][0] == ',' and corpus2_words[i+3] == 'and':\n",
    "            if corpus2_words[i+2][1] == 'JJ' and corpus2_words[i+4][1] == 'JJ':\n",
    "                # X, _ and _\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] -= 1\n",
    "                if lexicon.get(corpus2_words[i+4][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+4][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+4][0]] -= 1\n",
    "        elif corpus2_words[i-1][0] == ',' and corpus2_words[i+1] == 'and':\n",
    "            if corpus2_words[i-2][1] == 'JJ' and corpus2_words[i+2][1] == 'JJ':\n",
    "                # _ , X and _\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] -= 1\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] -= 1\n",
    "        elif corpus2_words[i-3][0] == ',' and corpus2_words[i-1] == 'and':\n",
    "            if corpus2_words[i-4][1] == 'JJ' and corpus2_words[i-2][1] == 'JJ':\n",
    "                # _ , _ and X\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] -= 1\n",
    "                if lexicon.get(corpus2_words[i-4][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-4][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-4][0]] -= 1\n",
    "    elif x in pos_init and i < len(corpus2_words)-1:\n",
    "        if corpus2_words[i-1][0] == 'and':\n",
    "            if corpus2_words[i-2][1] == 'JJ':\n",
    "                # _ and X\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] += 1\n",
    "        elif corpus2_words[i-1][0] == 'but' or corpus2_words[i-1][0] == 'rather':\n",
    "            if corpus2_words[i-2][1] == 'JJ':\n",
    "                # _ but X / _ rather X\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] -= 1\n",
    "        elif corpus2_words[i-2][0] == 'but' or corpus2_words[i-2][0] == 'rather':\n",
    "            if corpus2_words[i-3][1] == 'JJ':\n",
    "                # _ but adv X / _ rather than X\n",
    "                if lexicon.get(corpus2_words[i-3][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-3][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-3][0]] -= 1\n",
    "        if corpus2_words[i+1][0] == 'and':\n",
    "            if corpus2_words[i+2][1] == 'JJ':\n",
    "                # X and _\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] += 1\n",
    "        elif corpus2_words[i+1][0] == 'but' or corpus2_words[i+1][0] == 'rather':\n",
    "            if corpus2_words[i+2][1] == 'JJ':\n",
    "                # X but _ / X rather _\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] -= 1\n",
    "            if corpus2_words[i+3][1] == 'JJ':\n",
    "                # X but adv _ / X rather than _\n",
    "                if lexicon.get(corpus2_words[i+3][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+3][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+3][0]] -= 1\n",
    "        if corpus2_words[i+1][0] == ',' and corpus2_words[i+3] == 'and':\n",
    "            if corpus2_words[i+2][1] == 'JJ' and corpus2_words[i+4][1] == 'JJ':\n",
    "                # X, _ and _\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] += 1\n",
    "                if lexicon.get(corpus2_words[i+4][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+4][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+4][0]] += 1\n",
    "        elif corpus2_words[i-1][0] == ',' and corpus2_words[i+1] == 'and':\n",
    "            if corpus2_words[i-2][1] == 'JJ' and corpus2_words[i+2][1] == 'JJ':\n",
    "                # _ , X and _\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] += 1\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] += 1\n",
    "        elif corpus2_words[i-3][0] == ',' and corpus2_words[i-1] == 'and':\n",
    "            if corpus2_words[i-4][1] == 'JJ' and corpus2_words[i-2][1] == 'JJ':\n",
    "                # _ , _ and X\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] += 1\n",
    "                if lexicon.get(corpus2_words[i-4][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-4][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-4][0]] += 1\n",
    "\n",
    "print(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_new = []\n",
    "pos_new = []\n",
    "for key, value in lexicon.items():\n",
    "    if value > 0:\n",
    "        pos_new.append(key)\n",
    "    elif value < 0:\n",
    "        neg_new.append(key)\n",
    "#     else:\n",
    "#         pos_new.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Lexicon after Bootstrapping:\n",
      "66\n",
      "['dead', 'slight', 'r-rated', 'unrecommendable', 'creepy', 'loud', 'raucous', 'grainy', 'sanguine', 'crude', 'unoriginal', 'ankle', 'dull', 'sappy', 'moodily', 'innocuous', 'dishonest', 'unfunny', 'mechanical', 'familiar', 'insistent', 'sophomoric', 'stereotypical', 'overwrought', 'neurotic', 'amateurish', 'lazy', 'monotonous', 'serious', 'spare', 'melodramatic', 'formulaic', 'cynical', 'concerned', 'offensive', 'repetitive', 'clownish', 'didactic', 'steady', 'dry', 'forceful', 'rough', 'leaden', 'predictable', 'mush-hearted', 'unentertaining', 'redundant', 'impenetrable', 'unsuccessful', 'affable', 'simple', 'average', 'sentimental', 'disturbing', 'silly', 'uneven', 'pretentious', 'smug', 'banal', 'sour', 'stupid', 'tedious', 'prosaic', 'muddled', 'slow', 'wooden']\n",
      "\n",
      "Positive Lexicon after Bootstrapping:\n",
      "94\n",
      "['sensual', 'accessible', 'lyrical', 'weird', 'meditative', 'gripping', 'sexual', 'stylish', 'powerful', 'interesting', 'naturalistic', 'funny', 'effective', 'good', 'handsome', 'flavorful', 'informative', 'sweet', 'enjoyable', 'resonant', 'clever', 'full', 'exciting', 'moral', 'flaky', 'exotic', 'charming', 'complex', 'light', 'ingenious', 'energetic', 'deeply', 'honorable', 'cerebral', 'touching', 'unsettling', 'absorbing', 'intriguing', 'engaged', 'rapturous', 'strong', 'realistic', 'inspiring', 'subtle', 'honest', 'romantic', 'talented', 'bold', 'good-looking', 'audacious', 'old', 'delectable', 'emotional', 'uplifting', 'frisky', 'free', 'authentic', 'unique', 'human', 'intense', 'quirky', 'richly', 'brutal', 'unaffected', 'unexpected', 'provocative', 'sad', 'entertaining', 'celebratory', 'beautiful', 'vital', 'thrilling', 'brilliant', 'satisfying', 'unsatisfying', 'plausible', 'suggestive', 'pithy', 'dramatic', 'smart', 'introspective', 'shot', 'true', 'unselfconscious', 'suspenseful', 'tricky', 'pure', 'delightful', 'claustrophobic', 'intellectual', 'poignant', 'religious', 'fresh', 'insightful']\n"
     ]
    }
   ],
   "source": [
    "neg_new = list(set(neg_new))\n",
    "pos_new = list(set(pos_new))\n",
    "print('Negative Lexicon after Bootstrapping:')\n",
    "print(len(neg_new))\n",
    "print(neg_new)\n",
    "print()\n",
    "print('Positive Lexicon after Bootstrapping:')\n",
    "print(len(pos_new))\n",
    "print(pos_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dead': -1000, 'slight': -1002, 'r-rated': -999, 'unrecommendable': -1000, 'creepy': -1000, 'loud': -1000, 'raucous': -1000, 'grainy': -1000, 'sanguine': -1000, 'crude': -1000, 'unoriginal': -1000, 'ankle': -1000, 'dull': -1007, 'sappy': -1003, 'moodily': -1000, 'innocuous': -1000, 'dishonest': -999, 'unfunny': -1002, 'mechanical': -1001, 'familiar': -1003, 'insistent': -1000, 'sophomoric': -1000, 'stereotypical': -1000, 'overwrought': -1000, 'neurotic': -999, 'amateurish': -1000, 'lazy': -1001, 'monotonous': -1000, 'serious': -1000, 'spare': -1000, 'melodramatic': -1001, 'formulaic': -1000, 'cynical': -1001, 'concerned': -1000, 'offensive': -1003, 'repetitive': -1003, 'clownish': -1000, 'didactic': -1000, 'steady': -1000, 'dry': -1000, 'forceful': -1000, 'rough': -1000, 'leaden': -1000, 'predictable': -1006, 'mush-hearted': -999, 'unentertaining': -1000, 'redundant': -1000, 'impenetrable': -1000, 'unsuccessful': -999, 'affable': -1000, 'simple': -1001, 'average': -1000, 'sentimental': -1001, 'disturbing': -999, 'silly': -1001, 'uneven': -1000, 'pretentious': -1001, 'smug': -1000, 'banal': -1000, 'sour': -999, 'stupid': -999, 'tedious': -1000, 'prosaic': -1000, 'muddled': -1000, 'slow': -1001, 'wooden': -1000, 'sensual': 1000, 'accessible': 1002, 'lyrical': 1002, 'weird': 1000, 'meditative': 1000, 'gripping': 999, 'sexual': 1000, 'stylish': 1003, 'powerful': 1003, 'interesting': 1003, 'naturalistic': 999, 'funny': 1023, 'effective': 1001, 'good': 1001, 'handsome': 1000, 'flavorful': 1000, 'informative': 1000, 'sweet': 1003, 'enjoyable': 1004, 'resonant': 1000, 'clever': 1004, 'full': 1000, 'exciting': 1000, 'moral': 1000, 'flaky': 1000, 'exotic': 999, 'charming': 1001, 'complex': 1001, 'light': 1000, 'ingenious': 1000, 'energetic': 1002, 'deeply': 1000, 'honorable': 1000, 'cerebral': 1000, 'touching': 1000, 'unsettling': 1000, 'absorbing': 999, 'intriguing': 1002, 'engaged': 1000, 'rapturous': 1000, 'strong': 1000, 'realistic': 1000, 'inspiring': 999, 'subtle': 1001, 'honest': 1000, 'romantic': 1006, 'talented': 1000, 'bold': 1000, 'good-looking': 999, 'audacious': 1000, 'old': 1000, 'delectable': 1000, 'emotional': 1004, 'uplifting': 1001, 'frisky': 1000, 'free': 1000, 'authentic': 1000, 'unique': 1000, 'human': 1000, 'intense': 1000, 'quirky': 1002, 'richly': 1000, 'brutal': 1001, 'unaffected': 1000, 'unexpected': 1000, 'provocative': 1001, 'sad': 1000, 'entertaining': 1009, 'celebratory': 1000, 'beautiful': 1000, 'vital': 1000, 'thrilling': 999, 'brilliant': 1001, 'satisfying': 1000, 'unsatisfying': 1000, 'plausible': 1000, 'suggestive': 1000, 'pithy': 1000, 'dramatic': 1000, 'smart': 1001, 'introspective': 999, 'shot': 1001, 'true': 1000, 'unselfconscious': 1000, 'suspenseful': 1000, 'tricky': 1000, 'pure': 1000, 'delightful': 1000, 'claustrophobic': 1000, 'intellectual': 1001, 'poignant': 1002, 'religious': 1000, 'fresh': 1006, 'insightful': 1002, 'derivative': -1, 'sugary': 1, 'forgettable': 0, 'fussy': -1, 'irrelevant': 1, 'nonsensical': -1, 'unfulfilling': -2, 'odd': 1, 'unendurable': 1, 'unremarkable': -1, 'inauthentic': -1, 'undernourished': 1, 'obvious': -2, 'rote': 1, 'tired': -1, 'super': -1, 'notorious': 1, 'unpersuasive': -1, 'vainglorious': 1, 'thoroughly': -2, 'boring': 1, 'manic': 1, 'torpid': -1, 'portentous': -1, 'sassy': 1, 'unwieldy': -1, 'professional': 1, 'preposterous': -1, 'utterly': 0, 'spiritual': 2, 'believable': 1, 'poorly': -1, 'cold': -1, 'different': 1, 'inconsistent': -1, 'miserable': -1, 'dreary': -2, 'turgid': -1, 'original': 2, 'ponderous': -2, 'short': 1, 'likable': 1, 'obnoxious': -1, 'insufferable': -1, 'convincing': 1, 'uninventive': -1, 'underutilized': -1, 'tepid': -1, 'suspense': -1, 'dedicated': 1, 'literate': 1, 'photographs': 1, 'playful': 1, 'new': 2, 'important': 1, 'horrid': 1, 'successful': 1, 'unpleasant': 1, 'rich': 3, 'resourceful': 1, 'furious': 1, 'parisian': -1, 'raw': 0, 'subversive': 1, 'popular': 1, 'comprehensive': 1, 'darkly': 1, 'empty': 1, 'unassuming': 1, 'warm': -1, 'dark': 2, 'compelling': 1, 'spirited': 1, 'hilarious': 2, 'direct': 1, 'understated': 1, 'frankly': 1, 'modest': 1, 'youthful': 1, 'young': 1, 'fearless': 1, 'thoughtful': -1, 'innocent': -1, 'prescient': 1, 'memorable': 1, 'civic': 1, 'paced': 1, 'universal': 1, 'cinemantic': 1, 'recessive': 1, 'humorous': 1, 'mysterious': 2, 'intimate': 1, 'genuine': 1, 'newfangled': 1, 'social': 1, 'satirical': 1, 'scary': 2, 'irresistible': 1, 'sexy': 1, 'alert': 1, 'amusing': 1, 'reflective': 1, 'confident': 1, 'strange': 1, 'incisive': -1, 'recognizable': 1, 'giddy': 1, 'glossy': 1, 'cultural': 1, 'haunting': 1, 'eccentric': 1, 'angry': 1, 'visceral': 1, 'wonderful': 1, 'sophisticated': 1, 'pat': -1, 'evil': 1, 'attractive': 1, 'gentle': 1, 'foreign': -1, 'stubborn': 1, 'ambitious': 1, 'android': 1, 'dimensional': 1, 'harrowing': 1, 'fun': 1, 'traditional': 1, 'unforced': 1, 'difficult': 1, 'weak': 1, 'uncinematic': -1, 'tasty': 1, 'engaging': 1}\n"
     ]
    }
   ],
   "source": [
    "# second iteration\n",
    "neg_init = neg_new\n",
    "pos_init = pos_new\n",
    "\n",
    "lexicon = {}\n",
    "for word in neg_init:\n",
    "    lexicon.update({word: -999})\n",
    "for word in pos_init:\n",
    "    lexicon.update({word: 999})\n",
    "\n",
    "# _ and X, X and _, _ but X, X but _ are the baseline patterns    \n",
    "for i in range(len(corpus2_words)):\n",
    "    x = corpus2_words[i][0]\n",
    "    if x in neg_init and i < len(corpus2_words)-1:\n",
    "        if corpus2_words[i-1][0] == 'and':\n",
    "            if corpus2_words[i-2][1] == 'JJ':\n",
    "                # _ and X\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] -= 1\n",
    "        elif corpus2_words[i-1][0] == 'but' or corpus2_words[i-1][0] == 'rather':\n",
    "            if corpus2_words[i-2][1] == 'JJ':\n",
    "                # _ but X / _ rather X\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] += 1\n",
    "        elif corpus2_words[i-2][0] == 'but' or corpus2_words[i-2][0] == 'rather':\n",
    "            if corpus2_words[i-3][1] == 'JJ':\n",
    "                # _ but adv X / _ rather than X\n",
    "                if lexicon.get(corpus2_words[i-3][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-3][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-3][0]] += 1\n",
    "        if corpus2_words[i+1][0] == 'and':\n",
    "            if corpus2_words[i+2][1] == 'JJ':\n",
    "                # X and _\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] -= 1\n",
    "        elif corpus2_words[i+1][0] == 'but' or corpus2_words[i+1][0] == 'rather':\n",
    "            if corpus2_words[i+2][1] == 'JJ':\n",
    "                # X but _ / X rather _\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] += 1\n",
    "            if corpus2_words[i+3][1] == 'JJ':\n",
    "                # X but adv _ / X rather than _\n",
    "                if lexicon.get(corpus2_words[i+3][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+3][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+3][0]] += 1\n",
    "        if corpus2_words[i+1][0] == ',' and corpus2_words[i+3] == 'and':\n",
    "            if corpus2_words[i+2][1] == 'JJ' and corpus2_words[i+4][1] == 'JJ':\n",
    "                # X, _ and _\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] -= 1\n",
    "                if lexicon.get(corpus2_words[i+4][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+4][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+4][0]] -= 1\n",
    "        elif corpus2_words[i-1][0] == ',' and corpus2_words[i+1] == 'and':\n",
    "            if corpus2_words[i-2][1] == 'JJ' and corpus2_words[i+2][1] == 'JJ':\n",
    "                # _ , X and _\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] -= 1\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] -= 1\n",
    "        elif corpus2_words[i-3][0] == ',' and corpus2_words[i-1] == 'and':\n",
    "            if corpus2_words[i-4][1] == 'JJ' and corpus2_words[i-2][1] == 'JJ':\n",
    "                # _ , _ and X\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] -= 1\n",
    "                if lexicon.get(corpus2_words[i-4][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-4][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-4][0]] -= 1\n",
    "    elif x in pos_init and i < len(corpus2_words)-1:\n",
    "        if corpus2_words[i-1][0] == 'and':\n",
    "            if corpus2_words[i-2][1] == 'JJ':\n",
    "                # _ and X\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] += 1\n",
    "        elif corpus2_words[i-1][0] == 'but' or corpus2_words[i-1][0] == 'rather':\n",
    "            if corpus2_words[i-2][1] == 'JJ':\n",
    "                # _ but X / _ rather X\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] -= 1\n",
    "        elif corpus2_words[i-2][0] == 'but' or corpus2_words[i-2][0] == 'rather':\n",
    "            if corpus2_words[i-3][1] == 'JJ':\n",
    "                # _ but adv X / _ rather than X\n",
    "                if lexicon.get(corpus2_words[i-3][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-3][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-3][0]] -= 1\n",
    "        if corpus2_words[i+1][0] == 'and':\n",
    "            if corpus2_words[i+2][1] == 'JJ':\n",
    "                # X and _\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] += 1\n",
    "        elif corpus2_words[i+1][0] == 'but' or corpus2_words[i+1][0] == 'rather':\n",
    "            if corpus2_words[i+2][1] == 'JJ':\n",
    "                # X but _ / X rather _\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] -= 1\n",
    "            if corpus2_words[i+3][1] == 'JJ':\n",
    "                # X but adv _ / X rather than _\n",
    "                if lexicon.get(corpus2_words[i+3][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+3][0]: -1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+3][0]] -= 1\n",
    "        if corpus2_words[i+1][0] == ',' and corpus2_words[i+3] == 'and':\n",
    "            if corpus2_words[i+2][1] == 'JJ' and corpus2_words[i+4][1] == 'JJ':\n",
    "                # X, _ and _\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] += 1\n",
    "                if lexicon.get(corpus2_words[i+4][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+4][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+4][0]] += 1\n",
    "        elif corpus2_words[i-1][0] == ',' and corpus2_words[i+1] == 'and':\n",
    "            if corpus2_words[i-2][1] == 'JJ' and corpus2_words[i+2][1] == 'JJ':\n",
    "                # _ , X and _\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] += 1\n",
    "                if lexicon.get(corpus2_words[i+2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i+2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i+2][0]] += 1\n",
    "        elif corpus2_words[i-3][0] == ',' and corpus2_words[i-1] == 'and':\n",
    "            if corpus2_words[i-4][1] == 'JJ' and corpus2_words[i-2][1] == 'JJ':\n",
    "                # _ , _ and X\n",
    "                if lexicon.get(corpus2_words[i-2][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-2][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-2][0]] += 1\n",
    "                if lexicon.get(corpus2_words[i-4][0]) == None:\n",
    "                    lexicon.update({corpus2_words[i-4][0]: 1})\n",
    "                else:\n",
    "                    lexicon[corpus2_words[i-4][0]] += 1\n",
    "\n",
    "print(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_new = []\n",
    "pos_new = []\n",
    "for key, value in lexicon.items():\n",
    "    if value > 0:\n",
    "        pos_new.append(key)\n",
    "    elif value < 0:\n",
    "        neg_new.append(key)\n",
    "#     else:\n",
    "#         pos_new.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Lexicon after Bootstrapping:\n",
      "102\n",
      "['super', 'loud', 'thoroughly', 'sanguine', 'nonsensical', 'ankle', 'sappy', 'moodily', 'innocuous', 'obvious', 'sophomoric', 'stereotypical', 'melodramatic', 'neurotic', 'serious', 'unremarkable', 'formulaic', 'unwieldy', 'repetitive', 'dreary', 'mush-hearted', 'simple', 'average', 'insufferable', 'inauthentic', 'uneven', 'smug', 'pretentious', 'tired', 'unpersuasive', 'dull', 'obnoxious', 'unfunny', 'mechanical', 'incisive', 'insistent', 'torpid', 'overwrought', 'amateurish', 'spare', 'warm', 'dry', 'rough', 'predictable', 'unentertaining', 'unsuccessful', 'innocent', 'sour', 'uncinematic', 'wooden', 'unrecommendable', 'ponderous', 'creepy', 'inconsistent', 'raucous', 'poorly', 'grainy', 'unoriginal', 'dishonest', 'familiar', 'turgid', 'uninventive', 'miserable', 'tepid', 'cynical', 'concerned', 'offensive', 'clownish', 'derivative', 'parisian', 'forceful', 'impenetrable', 'affable', 'sentimental', 'disturbing', 'suspense', 'stupid', 'tedious', 'fussy', 'muddled', 'slow', 'preposterous', 'unfulfilling', 'dead', 'slight', 'r-rated', 'crude', 'underutilized', 'cold', 'monotonous', 'lazy', 'pat', 'didactic', 'steady', 'leaden', 'thoughtful', 'redundant', 'silly', 'foreign', 'banal', 'portentous', 'prosaic']\n",
      "\n",
      "Positive Lexicon after Bootstrapping:\n",
      "189\n",
      "['boring', 'sensual', 'professional', 'eccentric', 'angry', 'genuine', 'accessible', 'comprehensive', 'lyrical', 'weird', 'meditative', 'recognizable', 'gripping', 'sexual', 'scary', 'stylish', 'notorious', 'powerful', 'android', 'interesting', 'successful', 'naturalistic', 'funny', 'youthful', 'frankly', 'effective', 'good', 'handsome', 'flavorful', 'universal', 'evil', 'amusing', 'giddy', 'informative', 'sassy', 'sweet', 'enjoyable', 'resonant', 'empty', 'humorous', 'clever', 'full', 'hilarious', 'moral', 'exciting', 'reflective', 'newfangled', 'flaky', 'unforced', 'fearless', 'rote', 'exotic', 'charming', 'intimate', 'difficult', 'complex', 'light', 'ingenious', 'understated', 'energetic', 'civic', 'unendurable', 'deeply', 'honorable', 'cerebral', 'touching', 'weak', 'horrid', 'cinemantic', 'unsettling', 'different', 'unpleasant', 'important', 'absorbing', 'intriguing', 'engaged', 'rapturous', 'strong', 'manic', 'spiritual', 'memorable', 'paced', 'realistic', 'glossy', 'inspiring', 'short', 'subtle', 'engaging', 'prescient', 'honest', 'romantic', 'talented', 'fun', 'dedicated', 'bold', 'good-looking', 'audacious', 'old', 'odd', 'delectable', 'emotional', 'playful', 'sophisticated', 'literate', 'photographs', 'sugary', 'uplifting', 'modest', 'frisky', 'social', 'cultural', 'tasty', 'free', 'dark', 'authentic', 'spirited', 'sexy', 'harrowing', 'mysterious', 'popular', 'visceral', 'stubborn', 'convincing', 'unique', 'human', 'confident', 'unassuming', 'intense', 'quirky', 'richly', 'brutal', 'unaffected', 'satirical', 'dimensional', 'unexpected', 'provocative', 'sad', 'entertaining', 'direct', 'furious', 'vainglorious', 'new', 'undernourished', 'celebratory', 'beautiful', 'irrelevant', 'vital', 'thrilling', 'brilliant', 'subversive', 'ambitious', 'recessive', 'satisfying', 'unsatisfying', 'plausible', 'suggestive', 'pithy', 'gentle', 'rich', 'attractive', 'dramatic', 'alert', 'smart', 'introspective', 'darkly', 'original', 'shot', 'true', 'unselfconscious', 'suspenseful', 'tricky', 'pure', 'traditional', 'young', 'delightful', 'believable', 'compelling', 'resourceful', 'claustrophobic', 'intellectual', 'poignant', 'religious', 'fresh', 'irresistible', 'insightful', 'strange', 'haunting', 'wonderful', 'likable']\n"
     ]
    }
   ],
   "source": [
    "neg_new = list(set(neg_new))\n",
    "pos_new = list(set(pos_new))\n",
    "print('Negative Lexicon after Bootstrapping:')\n",
    "print(len(neg_new))\n",
    "print(neg_new)\n",
    "print()\n",
    "print('Positive Lexicon after Bootstrapping:')\n",
    "print(len(pos_new))\n",
    "print(pos_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
